{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4022d02-c52f-47b3-b937-fcec1cd109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "import cv2\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.ndimage.morphology import binary_dilation\n",
    "from skimage.io import imread_collection\n",
    "\n",
    "'''from tensorflow.keras import models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical'''\n",
    "\n",
    "current_directory = Path(__file__).resolve().parent\n",
    "\n",
    "train_new_model = False\n",
    "option = input(\"Quieres entrar un nuevo MODELO? (y/n): \")\n",
    "if option in [\"y\", \"Y\"]:\n",
    "    train_new_model = True\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "if train_new_model:\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        512, activation='relu', input_shape=(28*28, )))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adamax()\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "    y_train = tf.keras.utils.to_categorical(y_train)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "    model.fit(x_train[:, :], y_train, epochs=6, batch_size=64)\n",
    "    model.save('handwritten_digits.model', save_format='h5')\n",
    "\n",
    "else:\n",
    "    model = tf.keras.models.load_model('handwritten_digits.model')\n",
    "\n",
    "\n",
    "def digit_recognition(image, height, width):\n",
    "    im_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "\n",
    "    threshold, bwImage = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "    ctrs, hier = cv2.findContours(\n",
    "        bwImage.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    detected_images = []\n",
    "\n",
    "    for rect in rects:\n",
    "        leng = int(rect[3] * 1.6)\n",
    "        pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "        pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "        roi = bwImage[pt1:pt1+leng, pt2:pt2+leng]\n",
    "        roi = cv2.resize(roi, (height, width), interpolation=cv2.INTER_AREA)\n",
    "        roi = cv2.dilate(roi, (3, 3))\n",
    "        detected_images.append(roi)\n",
    "    cv2.waitKey()\n",
    "    predicted = []\n",
    "    convertedImage = detected_images\n",
    "    for i in range(len(convertedImage)):\n",
    "        predict = model.predict(np.reshape(convertedImage[i], (1, 784)))\n",
    "        predicted.append(predict.argmax())\n",
    "    y = 0\n",
    "    for rect in rects:\n",
    "        cv2.rectangle(image, (rect[0], rect[1]), (rect[0] +\n",
    "                      rect[2], rect[1] + rect[3]), (0, 255, 0), 3)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        fontScale = 4\n",
    "        color = (255, 0, 0)\n",
    "        thickness = 2\n",
    "        cv2.putText(image, str(\n",
    "            predicted[y]), (rect[0], rect[1]), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        y = y + 1\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def convert(lst):\n",
    "    s = [str(i) for i in lst]\n",
    "    res = int(\"\".join(s))\n",
    "    return (res)\n",
    "\n",
    "\n",
    "path = f\"{current_directory}/content/\"\n",
    "err = []\n",
    "img = []\n",
    "valid_images = [\".jpg\", \".gif\", \".png\", \".jpeg\"]\n",
    "predicted_rst = []\n",
    "actual_rst = []\n",
    "\n",
    "for f in os.listdir(path):\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    nm, e = f.split('.')\n",
    "    image = cv2.imread(os.path.join(path, f))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    try:\n",
    "        predicted_rst.append(digit_recognition(image, 28, 28))\n",
    "        img.append(image)\n",
    "        actual_rst.append(nm)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    except:\n",
    "        err.append(nm)\n",
    "\n",
    "correct_predictions = 0\n",
    "for k in range(0, len(img)):\n",
    "    if (int(actual_rst[k]) == convert(predicted_rst[k])):\n",
    "        correct_predictions = correct_predictions + 1\n",
    "\n",
    "accuracy = (correct_predictions/len(img))*100\n",
    "# print(\"Accuracy of the model is: \", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
